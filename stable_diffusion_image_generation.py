# -*- coding: utf-8 -*-
"""Stable-Diffusion-Image-Generation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Avn4blB3adhyJAuagxmFuIH9g9na3bIg

## **Stable Diffusion Image Generation**

This notebook demonstrates how to use the Stable Diffusion model to generate images based on text prompts. We will use libraries from Hugging Face for this purpose.

## Step 1: Install Required Libraries

---

First, we need to install the necessary libraries. Run the cell below to install them.
"""

!pip install diffusers transformers accelerate scipy ftfy

"""# Step 2: Import Required Libraries
Next, we import the libraries we need for this project.
"""

import torch
from torch import autocast
from diffusers import StableDiffusionPipeline
from PIL import Image
import IPython.display as display

"""# Step 3: Authenticate with Hugging Face Hub"""

from huggingface_hub import login
login(token="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")

"""# Step 4: Load Stable Diffusion Model
We will load the pre-trained Stable Diffusion model from the Hugging Face model hub. The model will run on GPU if available, otherwise on CPU.
"""

model_id = "CompVis/stable-diffusion-v1-4"
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load the pipeline with float16 precision for faster and optimized performance
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipe.to(device)

"""# Step 5: Create the Image Generation Function
Now, we define a function to generate images based on text prompts using the Stable Diffusion model.
"""

def generate_image(prompt, num_inference_steps=50, guidance_scale=7.5, width=512, height=512):
    """
    Generates an image based on the text prompt using Stable Diffusion.

    Args:
    - prompt (str): The text description to guide the image generation.
    - num_inference_steps (int): Number of diffusion steps for more refinement (default: 50).
    - guidance_scale (float): How strongly to follow the prompt (higher = more focused).
    - width (int): Width of the output image.
    - height (int): Height of the output image.

    Returns:
    - image (PIL.Image): The generated image.
    """
    # Ensuring model's performance through autocast
    with autocast("cuda"):
        image = pipe(prompt,
                     num_inference_steps=num_inference_steps,
                     guidance_scale=guidance_scale,
                     width=width,
                     height=height).images[0]
    return image

"""# Step 6: Define Advanced Customizations
We also define a function to generate multiple images from a list of text prompts.
"""

def generate_multiple_images(prompt_list, steps=50, scale=7.5):
    """
    Generates a series of images based on a list of text prompts.

    Args:
    - prompt_list (list): List of text prompts.
    - steps (int): Number of diffusion steps.
    - scale (float): Guidance scale for controlling text adherence.

    Returns:
    - List of generated images.
    """
    images = []
    for prompt in prompt_list:
        image = generate_image(prompt, num_inference_steps=steps, guidance_scale=scale)
        images.append(image)
        display.display(image)
    return images

"""# Step 7: Testing with Sample Prompts
Let's generate an image based on a sample prompt.
"""

sample_prompt = "A futuristic city floating in the clouds, with neon lights and flying cars."
image = generate_image(sample_prompt)

# Display the generated image
display.display(image)

# Save the generated image to file (optional)
image.save("sample_image.png")

"""# Step 8: Generating Multiple Images
We can generate multiple images from different prompts. Here is an example:
"""

prompts = [
    "A beautiful landscape with mountains and rivers",
    "A futuristic robot standing in a desert",
    "A dream-like fantasy forest with glowing trees"
]

generated_images = generate_multiple_images(prompts)

"""# Step 9: Fine-tuning Parameters (Optional)
We can try changing num_inference_steps and guidance_scale to see their effects:

num_inference_steps: Higher values refine the image quality but take more time.

guidance_scale: Larger values make the image more closely resemble the text prompt
"""

# Example of fine-tuning parameters
fine_tuned_image = generate_image("A majestic castle on a hill during sunset", num_inference_steps=75, guidance_scale=10.0)
display.display(fine_tuned_image)